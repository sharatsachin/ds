# Linear Regression

## What is Linear Regression?

Linear regression is a linear approach to modeling the relationship between a dependent variable and one or more independent variables. In linear regression, the relationships are modeled using linear predictor functions whose unknown model parameters are estimated from the data. It is mostly used for finding out the relationship between variables and the target variable.

## What are the assumptions behind linear regression?

## What is Homoscedasticity in the assumption?

## What will happen (challenges) if we try to predict categorical values using linear regression? (Using a threshold)

## What is the loss function of linear regression?

## Why we divide the value by 2 in loss function?

## Why we use square & root under in loss function why not take the absolute value?

## How do we optimize the loss function?

## What is the formula for new theta value (old theta â€“ lambda* d/dx)?

## What is d/dx here?

## What is R**2 and importance of it?

## What is VIF?

## What is the difference between R**2 & Adjusted R**2?

## What are the different metrics for the model evaluation?

## How do we handle over fitting problem?

## What are the different techniques of Regularization?

## What is the math behind Lasso & Ridge & Elastic Net?

## What is the difference between Lasso & Ridge & Elastic Net?